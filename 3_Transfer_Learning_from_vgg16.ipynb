{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal: classify images CATS vs DOGS, starting from vgg16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"data/dogs-vs-cats/train/\"\n",
    "valid_path = \"data/dogs-vs-cats/valid\"\n",
    "test_path = \"data/dogs-vs-cats/test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1000 images belonging to 2 classes.\n",
      "Found 200 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#1. Preprocessing\n",
    "\n",
    "## Put the images in a format that Keras actually likes (keras generators)\n",
    "## Qua in sintesti dico: le varie immagini sono una diversa dall'altra:\n",
    "## Vedi che devi fare, le voglio tutte in formato 224, 224\n",
    "## Sostanzialmente sta facendo il preprocessing come Ã¨ fatto nella vgg16\n",
    "## Nell'immagine, ogni pixel ha, se ho capito bene (R,G,B) una tripletta di rosso, verde, blu\n",
    "## vgg16 prende il training set, calcola la media del rosso, R_, media del verde, G_ e del blu B_\n",
    "## e dopo, immagine per immagine, (R,G,B) --> (R - R_, G -G_, B-B_) \n",
    "## Quindi i colori dopo il pre-processing sono un po' strani all'occhio umano\n",
    "train_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    ".flow_from_directory(directory=train_path, target_size=(224,224), classes=[\"cat\",\"dog\"], batch_size=10)\n",
    "\n",
    "valid_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    ".flow_from_directory(directory=valid_path, target_size=(224,224), classes=[\"cat\",\"dog\"], batch_size=10)\n",
    "\n",
    "test_batches = ImageDataGenerator(preprocessing_function=tf.keras.applications.vgg16.preprocess_input) \\\n",
    ".flow_from_directory(directory=test_path, target_size=(224,224), classes=[\"cat\",\"dog\"], batch_size=10, shuffle=False)\n",
    "\n",
    "assert train_batches.n == 1000\n",
    "assert valid_batches.n == 200\n",
    "assert test_batches.n == 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 65s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Download the model vgg16 (The first time takes time :)\n",
    "vgg16_model = tf.keras.applications.vgg16.VGG16()\n",
    "vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    non_trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in model.non_trainable_weights])\n",
    "    trainable_params = np.sum([np.prod(v.get_shape().as_list()) for v in model.trainable_weights])\n",
    "    return {\"non_trainable_params\": non_trainable_params, \"trainable_params\": trainable_params}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = count_params(vgg16_model)\n",
    "assert params['non_trainable_params'] == 0\n",
    "assert params[\"trainable_params\"] == 138357544"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 8194      \n",
      "=================================================================\n",
      "Total params: 134,268,738\n",
      "Trainable params: 8,194\n",
      "Non-trainable params: 134,260,544\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## E ora creiamo il nostro modello. (FIGHISSIMO)\n",
    "## In pratica copio tutto da vgg16, tranne l'ultimo output layer, che NON includo\n",
    "model = Sequential()\n",
    "for layer in vgg16_model.layers[:-1]:\n",
    "    model.add(layer)\n",
    "    \n",
    "## Freeziamo tutto --> Non voglio re-trainarli !!\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "## E infine aggiungiamo quello che serve a noi. La distinzione tra cats and dogs\n",
    "model.add(Dense(units=2, activation=\"softmax\"))\n",
    "    \n",
    "    \n",
    "## NOTA BENE: nel summary devi vedere che i trainable_params sono TUTTI e SOLI quelli dell'ultimo layer!\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "100/100 - 166s - loss: 0.3343 - accuracy: 0.8650 - val_loss: 0.1161 - val_accuracy: 0.9600\n",
      "Epoch 2/5\n",
      "100/100 - 168s - loss: 0.0947 - accuracy: 0.9680 - val_loss: 0.0848 - val_accuracy: 0.9550\n",
      "Epoch 3/5\n",
      "100/100 - 167s - loss: 0.0609 - accuracy: 0.9770 - val_loss: 0.0768 - val_accuracy: 0.9700\n",
      "Epoch 4/5\n",
      "100/100 - 167s - loss: 0.0428 - accuracy: 0.9840 - val_loss: 0.0732 - val_accuracy: 0.9800\n",
      "Epoch 5/5\n",
      "100/100 - 167s - loss: 0.0318 - accuracy: 0.9900 - val_loss: 0.0693 - val_accuracy: 0.9800\n"
     ]
    }
   ],
   "source": [
    "## TRAIN (much better than before :)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(x=train_batches, validation_data=valid_batches, epochs=5, verbose=2)\n",
    "assert model.history.history.get(\"accuracy\")[-1] > 0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  1]\n",
      " [47  3]]\n",
      "{'cat': 0, 'dog': 1}\n"
     ]
    }
   ],
   "source": [
    "## PREDICT\n",
    "predictions = model.predict(x=test_batches, verbose=0)\n",
    "cm = confusion_matrix(y_true=test_batches.classes, y_pred=np.argmax(predictions,axis=-1))\n",
    "print(cm)\n",
    "print(test_batches.class_indices)\n",
    "\n",
    "## NOTA BENE: occhio nella lettura del print: le categorie diagonali NON appaiono printate in diagonale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
